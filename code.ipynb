{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda env remove --name ev4nlpCr\n",
    "conda create -n ev4nlpCr2 python=3.10.13\n",
    "conda activate ev4nlpCr2\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "pip install numpy tqdm pandas matplotlib packaging argparse transformers\n",
    "\n",
    "\n",
    "conda remove --name myenv --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET TRANSLATION5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpt-3.5-turbo API(1s/t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TP3:Please provide the English translation for these sentences:\n",
      "\n",
      "849/1200 |850/1200 |\n",
      "851/1200 |852/1200 |853/1200 |854/1200 |855/1200 |856/1200 |Error[3,857]: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n",
      "858/1200 |859/1200 |860/1200 |\n",
      "861/1200 |862/1200 |863/1200 |864/1200 |865/1200 |866/1200 |867/1200 |868/1200 |869/1200 |870/1200 |\n",
      "871/1200 |872/1200 |873/1200 |874/1200 |875/1200 |876/1200 |877/1200 |878/1200 |879/1200 |880/1200 |\n",
      "881/1200 |882/1200 |883/1200 |884/1200 |885/1200 |886/1200 |887/1200 |888/1200 |889/1200 |890/1200 |\n",
      "891/1200 |892/1200 |893/1200 |894/1200 |895/1200 |896/1200 |897/1200 |898/1200 |899/1200 |900/1200 |\n",
      "901/1200 |902/1200 |903/1200 |904/1200 |905/1200 |906/1200 |907/1200 |908/1200 |909/1200 |910/1200 |\n",
      "911/1200 |912/1200 |913/1200 |914/1200 |915/1200 |916/1200 |917/1200 |918/1200 |919/1200 |920/1200 |\n",
      "921/1200 |922/1200 |923/1200 |924/1200 |925/1200 |926/1200 |927/1200 |928/1200 |929/1200 |930/1200 |\n",
      "931/1200 |932/1200 |933/1200 |934/1200 |935/1200 |936/1200 |937/1200 |938/1200 |939/1200 |940/1200 |\n",
      "941/1200 |942/1200 |943/1200 |944/1200 |945/1200 |946/1200 |947/1200 |948/1200 |949/1200 |950/1200 |\n",
      "951/1200 |952/1200 |953/1200 |954/1200 |955/1200 |956/1200 |957/1200 |958/1200 |959/1200 |960/1200 |\n",
      "961/1200 |962/1200 |963/1200 |964/1200 |965/1200 |966/1200 |967/1200 |968/1200 |969/1200 |970/1200 |\n",
      "971/1200 |972/1200 |973/1200 |974/1200 |975/1200 |976/1200 |977/1200 |978/1200 |979/1200 |980/1200 |\n",
      "981/1200 |982/1200 |983/1200 |984/1200 |985/1200 |986/1200 |987/1200 |988/1200 |Error[3,989]: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n",
      "990/1200 |\n",
      "991/1200 |992/1200 |993/1200 |994/1200 |995/1200 |996/1200 |997/1200 |998/1200 |999/1200 |1000/1200 |\n",
      "1001/1200 |1002/1200 |1003/1200 |1004/1200 |1005/1200 |1006/1200 |1007/1200 |1008/1200 |1009/1200 |1010/1200 |\n",
      "1011/1200 |1012/1200 |1013/1200 |1014/1200 |1015/1200 |1016/1200 |1017/1200 |1018/1200 |1019/1200 |1020/1200 |\n",
      "1021/1200 |1022/1200 |1023/1200 |1024/1200 |1025/1200 |1026/1200 |1027/1200 |1028/1200 |1029/1200 |1030/1200 |\n",
      "1031/1200 |1032/1200 |1033/1200 |1034/1200 |1035/1200 |1036/1200 |1037/1200 |1038/1200 |1039/1200 |1040/1200 |\n",
      "1041/1200 |1042/1200 |1043/1200 |1044/1200 |1045/1200 |1046/1200 |1047/1200 |1048/1200 |1049/1200 |1050/1200 |\n",
      "1051/1200 |1052/1200 |1053/1200 |1054/1200 |1055/1200 |1056/1200 |1057/1200 |1058/1200 |1059/1200 |1060/1200 |\n",
      "1061/1200 |1062/1200 |1063/1200 |1064/1200 |1065/1200 |1066/1200 |1067/1200 |1068/1200 |1069/1200 |1070/1200 |\n",
      "1071/1200 |1072/1200 |1073/1200 |1074/1200 |1075/1200 |1076/1200 |1077/1200 |1078/1200 |1079/1200 |Error[3,1080]: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n",
      "1081/1200 |1082/1200 |1083/1200 |1084/1200 |1085/1200 |1086/1200 |1087/1200 |1088/1200 |1089/1200 |1090/1200 |\n",
      "1091/1200 |1092/1200 |1093/1200 |1094/1200 |1095/1200 |1096/1200 |1097/1200 |1098/1200 |1099/1200 |1100/1200 |\n",
      "1101/1200 |1102/1200 |1103/1200 |1104/1200 |1105/1200 |1106/1200 |1107/1200 |1108/1200 |1109/1200 |1110/1200 |\n",
      "1111/1200 |1112/1200 |1113/1200 |1114/1200 |1115/1200 |1116/1200 |1117/1200 |1118/1200 |1119/1200 |1120/1200 |\n",
      "1121/1200 |1122/1200 |1123/1200 |1124/1200 |1125/1200 |1126/1200 |1127/1200 |1128/1200 |1129/1200 |1130/1200 |\n",
      "1131/1200 |1132/1200 |Error[3,1133]: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n",
      "Error[3,1134]: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n",
      "1135/1200 |1136/1200 |1137/1200 |1138/1200 |1139/1200 |1140/1200 |\n",
      "1141/1200 |1142/1200 |1143/1200 |1144/1200 |1145/1200 |1146/1200 |1147/1200 |1148/1200 |1149/1200 |1150/1200 |\n",
      "1151/1200 |1152/1200 |1153/1200 |1154/1200 |1155/1200 |1156/1200 |1157/1200 |1158/1200 |1159/1200 |1160/1200 |\n",
      "1161/1200 |1162/1200 |1163/1200 |1164/1200 |1165/1200 |1166/1200 |1167/1200 |1168/1200 |1169/1200 |1170/1200 |\n",
      "1171/1200 |1172/1200 |1173/1200 |1174/1200 |1175/1200 |1176/1200 |1177/1200 |1178/1200 |1179/1200 |1180/1200 |\n",
      "1181/1200 |1182/1200 |1183/1200 |1184/1200 |1185/1200 |1186/1200 |1187/1200 |1188/1200 |1189/1200 |1190/1200 |\n",
      "1191/1200 |1192/1200 |1193/1200 |1194/1200 |1195/1200 |1196/1200 |1197/1200 |Error[3,1198]: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n",
      "1199/1200 |1200/1200 |\n"
     ]
    }
   ],
   "source": [
    "# test openai.ChatCompletion.create\n",
    "import openai\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "with open('dataset/zh.source', 'r', encoding='utf-8') as file:\n",
    "    ls_zhData = file.readlines()\n",
    "\n",
    "with open('openai.api_key', 'r', encoding='utf-8') as file:\n",
    "    openai.api_key = file.readlines()[0]\n",
    "\n",
    "TPs = [\n",
    "'Translate these sentences from Chinese to English:\\n',  \n",
    "'Answer with no quotes. What do these sentences mean in English?\\n', \n",
    "'Please provide the English translation for these sentences:\\n'\n",
    "]\n",
    "\n",
    "\n",
    "start_tpi = -1\n",
    "start_nlsi = -1\n",
    "# 获取当前文件夹中的所有文件\n",
    "files = os.listdir('.')\n",
    "# 筛选出所有满足条件的文件，获取其中的数字部分，并转化为整数\n",
    "nums = [int(re.search(r'tp(\\d+)_translated_sentences\\.txt', f).group(1)) for f in files if re.match(r'tp(\\d+)_translated_sentences\\.txt', f)]\n",
    "# 获取最大的数字，如果没有满足条件的文件则返回None\n",
    "start_tpi = max(nums) if nums else None\n",
    "# 如果存在满足条件的文件\n",
    "if start_tpi is not None:\n",
    "    # 读取对应文件的倒数第二行\n",
    "    with open(f'tp{start_tpi}_translated_sentences.txt', 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        if len(lines) >= 2:\n",
    "            s = re.search(r'\\[(.*?)\\]', lines[-1])\n",
    "            s = s.group(1) if s else None\n",
    "            start_nlsi = int(s)+1\n",
    "\n",
    "tpi = 1\n",
    "while tpi <= len(TPs):\n",
    "    if start_tpi != -1:\n",
    "        tpi = start_tpi\n",
    "        start_tpi = -1\n",
    "    tp = TPs[tpi - 1]  # adjust index here\n",
    "    print('\\nTP'+str(tpi)+':'+tp)\n",
    "    # if start_tpi == -1:\n",
    "    #     with open('tp'+str(tpi)+'_translated_sentences.txt', 'a+', encoding='utf-8') as f:\n",
    "    #         f.write(\"TP%d: %s\\n\" % (tpi, tp))\n",
    "    # 4. 循环询问GPT\n",
    "    lsAns = []  # 用于存储GPT的回答\n",
    "    nlsi = 1\n",
    "    while nlsi <= len(ls_zhData):\n",
    "        if start_nlsi != -1:\n",
    "            nlsi = start_nlsi\n",
    "            start_nlsi = -1\n",
    "        unit = ls_zhData[nlsi - 1]  # adjust index here\n",
    "        askContent = tp + \"\".join(unit)\n",
    "        # print(askContent)\n",
    "        # if True:\n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                { \n",
    "                \"role\": \"user\",\n",
    "                \"content\": askContent\n",
    "                } \n",
    "        ]\n",
    "        )\n",
    "            ans = completion.choices[0].message[\"content\"]\n",
    "            lsAns.append(ans)\n",
    "            print(\"%d/%d\" % (nlsi, len(ls_zhData)), end=' |')\n",
    "            if nlsi % 10 == 0:\n",
    "                print()\n",
    "        except Exception as e:\n",
    "            ans = \"Error[%d,%d]: %s\" % (tpi, nlsi, str(e))\n",
    "            print(ans)\n",
    "            start_tpi = tpi\n",
    "            start_nlsi = nlsi + 1\n",
    "        # print(ans)\n",
    "        # print('\\n'+'-'*10+'\\n')\n",
    "    \n",
    "        # 5. 保存C到文件\n",
    "        with open('tp'+str(tpi)+'_translated_sentences.txt', 'a+', encoding='utf-8') as f:\n",
    "            f.write(\"[%d]:%s\\n\" % (nlsi, ans))\n",
    "        # time.sleep(0.02)\n",
    "        nlsi += 1\n",
    "    tpi += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual Translation for Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TP3:Please provide the English translation for these sentences:\n",
      "\n",
      "Please provide the English translation for these sentences:\n",
      "这句话是引用古书里的。\n",
      "\n",
      "1001/1200 |This sentence is a quotation from an ancient book.\n"
     ]
    }
   ],
   "source": [
    "# test openai.ChatCompletion.create\n",
    "\n",
    "import openai\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "with open('dataset/zh.source', 'r', encoding='utf-8') as file:\n",
    "    ls_zhData = file.readlines()\n",
    "\n",
    "\n",
    "with open('openai.api_key', 'r', encoding='utf-8') as file:\n",
    "    openai.api_key = file.readlines()[0]\n",
    "\n",
    "TPs = [\n",
    "'Translate these sentences from Chinese to English:\\n',  \n",
    "'Answer with no quotes. What do these sentences mean in English?\\n', \n",
    "'Please provide the English translation for these sentences:\\n'\n",
    "]\n",
    "\n",
    "\n",
    "tpi = 3\n",
    "nlsi = 1001\n",
    "if True:\n",
    "    tp = TPs[tpi - 1]  # adjust index here\n",
    "    print('\\nTP'+str(tpi)+':'+tp)\n",
    "    lsAns = []  # 用于存储GPT的回答\n",
    "    if True:\n",
    "        unit = ls_zhData[nlsi - 1]  # adjust index here\n",
    "        askContent = tp + \"\".join(unit)\n",
    "        print(askContent)\n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                { \n",
    "                \"role\": \"user\",\n",
    "                \"content\": askContent\n",
    "                } \n",
    "        ]\n",
    "        )\n",
    "            ans = completion.choices[0].message[\"content\"]\n",
    "            lsAns.append(ans)\n",
    "            print(\"%d/%d\" % (nlsi, len(ls_zhData)), end=' |')\n",
    "        except Exception as e:\n",
    "            ans = \"Error[%d,%d]: %s\" % (tpi, nlsi, str(e))\n",
    "            print(ans)\n",
    "            start_tpi = tpi\n",
    "            start_nlsi = nlsi + 1\n",
    "        print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLLB API(1s/t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLLB Sample\n",
    "https://huggingface.co/docs/transformers/model_doc/nllb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please ask me where you come from.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# 初始化分词器和模型，设置源语言为中文（'zh'），目标语言为英文（'eng_Latn'）\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=\"zh\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "\n",
    "# 待翻译的中文句子\n",
    "chinese_sentence = \"请问你来自哪里？\"\n",
    "\n",
    "# 对句子进行编码\n",
    "inputs = tokenizer(chinese_sentence, return_tensors=\"pt\")\n",
    "\n",
    "# 使用模型生成翻译的输出，并强制目标语言为英文\n",
    "translated_tokens = model.generate(\n",
    "    **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"eng_Latn\"]\n",
    ")\n",
    "\n",
    "# 解码模型输出的tokens，得到翻译后的英文句子\n",
    "translated_sentence = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "\n",
    "print(translated_sentence)  # 输出翻译后的英文句子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLLB translation\n",
    "- run code with stop\n",
    "- clear 'zh' in tanslated output\n",
    "- run second cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 检查是否有可用的 CUDA 设备并设置 device 变量\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 初始化 tokenizer 和 model，并将模型移动到设定的设备上\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=\"zh\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\").to(device)\n",
    "\n",
    "def nllb_zh2en(srczh):\n",
    "    chinese_sentence = srczh\n",
    "    # 将输入数据移动到同一设备上\n",
    "    inputs = tokenizer(chinese_sentence, return_tensors=\"pt\").to(device)\n",
    "    translated_tokens = model.generate(\n",
    "        **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"eng_Latn\"]\n",
    "    )\n",
    "    translated_sentence = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "    opten = translated_sentence.strip()\n",
    "    return opten\n",
    "\n",
    "list_path_src_dataset = ['zh.source1.CL_SA450', 'zh.source2.CT-SA350', 'zh.source3.LA400']\n",
    "\n",
    "for path in list_path_src_dataset:\n",
    "    path_src_dataset = 'dataset/' + path\n",
    "    path_opt_tslt = 'translated/NLLB_API/' + 'NLLB_' + path + '_tslt_en.txt'\n",
    "    \n",
    "    with open(path_src_dataset, 'r', encoding='utf-8') as fin:\n",
    "        list_src_dataset = fin.readlines()\n",
    "    \n",
    "    list_opt_tslt = []\n",
    "    \n",
    "    for line_src in tqdm(list_src_dataset, desc=f\"Translating {path}\"):\n",
    "        list_opt_tslt.append(nllb_zh2en(line_src))\n",
    "    \n",
    "    with open(path_opt_tslt, 'a+', encoding='utf-8') as fout:\n",
    "        for line_opt_tslt in list_opt_tslt:\n",
    "            fout.write(line_opt_tslt + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in list_path_src_dataset:\n",
    "    path_src_dataset = 'translated/NLLB_API/' + 'NLLB_' + path + '_tslt_en.txt'\n",
    "    path_opt_tslt = 'translated/NLLB_API/' + 'NLLB_' + 'zh.source' + '_tslt_en.txt'\n",
    "    with open(path_src_dataset, 'r', encoding='utf-8') as fin:\n",
    "        with open(path_opt_tslt, 'a+', encoding='utf-8') as fout:\n",
    "            for line_fin in fin:\n",
    "                fout.write(line_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google API(1s/t)\n",
    "- using google translation directly\n",
    "- combine translation text using cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in list_path_src_dataset:\n",
    "    path_src_dataset = 'translated/Google_API/' + 'Google_' + path + '_tslt_en.txt'\n",
    "    path_opt_tslt = 'translated/Google_API/' + 'Google_' + 'zh.source' + '_tslt_en.txt'\n",
    "    with open(path_src_dataset, 'r', encoding='utf-8') as fin:\n",
    "        with open(path_opt_tslt, 'a+', encoding='utf-8') as fout:\n",
    "            for line_fin in fin:\n",
    "                fout.write(line_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepL API(1s/t)\n",
    "- using google translation directly\n",
    "- combine translation text using cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in list_path_src_dataset:\n",
    "    path_src_dataset = 'translated/DeepL_API/' + 'DeepL_' + path + '_tslt_en.txt'\n",
    "    path_opt_tslt = 'translated/DeepL_API/' + 'DeepL_' + 'zh.source' + '_tslt_en.txt'\n",
    "    with open(path_src_dataset, 'r', encoding='utf-8') as fin:\n",
    "        with open(path_opt_tslt, 'a+', encoding='utf-8') as fout:\n",
    "            for line_fin in fin:\n",
    "                fout.write(line_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get ref+tslts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文件\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [line.strip() for line in lines]\n",
    "\n",
    "ref_file = 'dataset/test.true.en'\n",
    "tslt_file = 'translated/tp1_tslt_en.txt'\n",
    "\n",
    "refs = read_file(ref_file)\n",
    "tslts = read_file(tslt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nltk corpus_bleu sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# corpus_bleu SAMPLE\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# 注意：在references中，每个参考句子都是一个列表的元素，即使只有一个参考句子\n",
    "references = [\n",
    "                [['this', 'is', 'test', 'one'], ['this', 'is', 'a', 'test', 'one']],\n",
    "                [['this', 'is', 'test', 'two'], ['this', 'is', 'a', 'test', 'two']]\n",
    "             ]\n",
    "candidates = [\n",
    "                ['this', 'is', 'test', 'one'],\n",
    "                ['this', 'is', 'test', 'two']\n",
    "             ]\n",
    "score = corpus_bleu(references, candidates)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nltk sentence_bleu sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# 注意：在references中，每个参考句子都是一个列表的元素，即使只有一个参考句子\n",
    "references = [\n",
    "    [['this', 'is', 'test', 'one'], ['this', 'is', 'a', 'test', 'one']],  # References for first sentence\n",
    "    [['this', 'is', 'test', 'two'], ['this', 'is', 'a', 'test', 'two']]   # References for second sentence\n",
    "]\n",
    "candidates = [\n",
    "    ['this', 'is', 'test', 'one'],  # Candidate for first sentence\n",
    "    ['this', 'is', 'test', 'two']   # Candidate for second sentence\n",
    "]\n",
    "\n",
    "scores = []\n",
    "for i in range(len(candidates)):\n",
    "    # Compute BLEU score for each candidate against its corresponding references\n",
    "    score = sentence_bleu(references[i], candidates[i])\n",
    "    scores.append(score)\n",
    "    print(f\"BLEU score for sentence {i+1}: {score}\")\n",
    "\n",
    "average_score = sum(scores) / len(scores)\n",
    "print(f\"Average BLEU score: {average_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLEU evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh.source1.CL_SA450|gpt-3.5-turbo|TP1|corpus_bleu = \n",
      "0.28158748958994156\n",
      "zh.source1.CL_SA450|gpt-3.5-turbo|TP2|corpus_bleu = \n",
      "0.2676698411320771\n",
      "zh.source1.CL_SA450|gpt-3.5-turbo|TP3|corpus_bleu = \n",
      "0.28026530722349025\n",
      "zh.source1.CL_SA450|NLLB|corpus_bleu = \n",
      "0.20273545322393868\n",
      "zh.source1.CL_SA450|Google|corpus_bleu = \n",
      "0.3321425941392817\n",
      "zh.source1.CL_SA450|DeepL|corpus_bleu = \n",
      "0.2518351994659602\n",
      "zh.source2.CT-SA350|gpt-3.5-turbo|TP1|corpus_bleu = \n",
      "0.3023981126241737\n",
      "zh.source2.CT-SA350|gpt-3.5-turbo|TP2|corpus_bleu = \n",
      "0.30422142800103963\n",
      "zh.source2.CT-SA350|gpt-3.5-turbo|TP3|corpus_bleu = \n",
      "0.3071332743320029\n",
      "zh.source2.CT-SA350|NLLB|corpus_bleu = \n",
      "0.27158369215542183\n",
      "zh.source2.CT-SA350|Google|corpus_bleu = \n",
      "0.38552247217268426\n",
      "zh.source2.CT-SA350|DeepL|corpus_bleu = \n",
      "0.33097287199675074\n",
      "zh.source3.LA400|gpt-3.5-turbo|TP1|corpus_bleu = \n",
      "0.33750745760901785\n",
      "zh.source3.LA400|gpt-3.5-turbo|TP2|corpus_bleu = \n",
      "0.3140026825973613\n",
      "zh.source3.LA400|gpt-3.5-turbo|TP3|corpus_bleu = \n",
      "0.337440908499803\n",
      "zh.source3.LA400|NLLB|corpus_bleu = \n",
      "0.2721862499281512\n",
      "zh.source3.LA400|Google|corpus_bleu = \n",
      "0.3827089228685418\n",
      "zh.source3.LA400|DeepL|corpus_bleu = \n",
      "0.312365578911962\n",
      "zh.source|gpt-3.5-turbo|TP1|corpus_bleu = \n",
      "0.3089671865725252\n",
      "zh.source|gpt-3.5-turbo|TP2|corpus_bleu = \n",
      "0.3003483421904474\n",
      "zh.source|gpt-3.5-turbo|TP3|corpus_bleu = \n",
      "0.3106092340997083\n",
      "zh.source|NLLB|corpus_bleu = \n",
      "0.2583708769199583\n",
      "zh.source|Google|corpus_bleu = \n",
      "0.37231138429389304\n",
      "zh.source|DeepL|corpus_bleu = \n",
      "0.30847628021964313\n"
     ]
    }
   ],
   "source": [
    "list_src_name = ['zh.source1.CL_SA450', 'zh.source2.CT-SA350', 'zh.source3.LA400', 'zh.source']\n",
    "list_ref_name = ['test.true.en1.CL_SA450', 'test.true.en2.CT-SA350', 'test.true.en3.LA400', 'test.true.en']\n",
    "# GPT individual\n",
    "list_tslt_folder = ['NLLB', 'Google', 'DeepL']\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [line.strip() for line in lines]\n",
    "\n",
    "for i_name in range(len(list_src_name)):\n",
    "    src_name = list_src_name[i_name]\n",
    "    ref_name = list_ref_name[i_name]\n",
    "\n",
    "    path_ref = 'dataset/'+ref_name\n",
    "    for tpi in range(1,3+1):\n",
    "        id_src = \"\"\n",
    "        if i_name != 3:\n",
    "            id_src = str(i_name+1)\n",
    "        path_tslt = 'translated/gpt-3.5-turbo_API/zh.source'+id_src+'_tp'+str(tpi)+'_tslt_en.txt'\n",
    "\n",
    "        refs = read_file(path_ref)\n",
    "        tslts = read_file(path_tslt)\n",
    "        refs_tok = [[wordpunct_tokenize(sentence)] for sentence in refs]\n",
    "        tslts_tok = [wordpunct_tokenize(sentence) for sentence in tslts]\n",
    "\n",
    "        print(\"%s|gpt-3.5-turbo|TP%d|corpus_bleu = \"%(src_name,tpi))\n",
    "        print(corpus_bleu(refs_tok, tslts_tok))\n",
    "\n",
    "    for tslt_name in list_tslt_folder:\n",
    "        path_tslt = 'translated/'+tslt_name+'_API/'+tslt_name+'_'+src_name+'_tslt_en.txt'\n",
    "\n",
    "        refs = read_file(path_ref)\n",
    "        tslts = read_file(path_tslt)\n",
    "        refs_tok = [[wordpunct_tokenize(sentence)] for sentence in refs]\n",
    "        tslts_tok = [wordpunct_tokenize(sentence) for sentence in tslts]\n",
    "\n",
    "        print(\"%s|%s|corpus_bleu = \"%(src_name,tslt_name))\n",
    "        print(corpus_bleu(refs_tok, tslts_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh.source1.CL_SA450|gpt-3.5-turbo|TP1|sentence_bleu_avg = \n",
      "0.18615906555104828\n",
      "zh.source1.CL_SA450|gpt-3.5-turbo|TP2|sentence_bleu_avg = \n",
      "0.17181308259304906\n",
      "zh.source1.CL_SA450|gpt-3.5-turbo|TP3|sentence_bleu_avg = \n",
      "0.18683988170872787\n",
      "zh.source1.CL_SA450|NLLB|sentence_bleu_avg = \n",
      "0.10667113832002532\n",
      "zh.source1.CL_SA450|Google|sentence_bleu_avg = \n",
      "0.23873082172811932\n",
      "zh.source1.CL_SA450|DeepL|sentence_bleu_avg = \n",
      "0.14436123486561894\n",
      "zh.source2.CT-SA350|gpt-3.5-turbo|TP1|sentence_bleu_avg = \n",
      "0.23984492293557577\n",
      "zh.source2.CT-SA350|gpt-3.5-turbo|TP2|sentence_bleu_avg = \n",
      "0.2472777687780489\n",
      "zh.source2.CT-SA350|gpt-3.5-turbo|TP3|sentence_bleu_avg = \n",
      "0.24719559619014989\n",
      "zh.source2.CT-SA350|NLLB|sentence_bleu_avg = \n",
      "0.20906048467225247\n",
      "zh.source2.CT-SA350|Google|sentence_bleu_avg = \n",
      "0.3339061660046424\n",
      "zh.source2.CT-SA350|DeepL|sentence_bleu_avg = \n",
      "0.27705301172915076\n",
      "zh.source3.LA400|gpt-3.5-turbo|TP1|sentence_bleu_avg = \n",
      "0.265747674271723\n",
      "zh.source3.LA400|gpt-3.5-turbo|TP2|sentence_bleu_avg = \n",
      "0.22813164646087167\n",
      "zh.source3.LA400|gpt-3.5-turbo|TP3|sentence_bleu_avg = \n",
      "0.2582921999240995\n",
      "zh.source3.LA400|NLLB|sentence_bleu_avg = \n",
      "0.1979679740290566\n",
      "zh.source3.LA400|Google|sentence_bleu_avg = \n",
      "0.2978677404128644\n",
      "zh.source3.LA400|DeepL|sentence_bleu_avg = \n",
      "0.22780615762973114\n",
      "zh.source|gpt-3.5-turbo|TP1|sentence_bleu_avg = \n",
      "0.22834697686176006\n",
      "zh.source|gpt-3.5-turbo|TP2|sentence_bleu_avg = \n",
      "0.2125964706862815\n",
      "zh.source|gpt-3.5-turbo|TP3|sentence_bleu_avg = \n",
      "0.22826107117093333\n",
      "zh.source|NLLB|sentence_bleu_avg = \n",
      "0.1669669762424353\n",
      "zh.source|Google|sentence_bleu_avg = \n",
      "0.286202603370354\n",
      "zh.source|DeepL|sentence_bleu_avg = \n",
      "0.2108779773721863\n"
     ]
    }
   ],
   "source": [
    "for i_name in range(len(list_src_name)):\n",
    "    src_name = list_src_name[i_name]\n",
    "    ref_name = list_ref_name[i_name]\n",
    "\n",
    "    path_ref = 'dataset/'+ref_name\n",
    "    for tpi in range(1,3+1):\n",
    "        id_src = \"\"\n",
    "        if i_name != 3:\n",
    "            id_src = str(i_name+1)\n",
    "        path_tslt = 'translated/gpt-3.5-turbo_API/zh.source'+id_src+'_tp'+str(tpi)+'_tslt_en.txt'\n",
    "\n",
    "        refs = read_file(path_ref)\n",
    "        tslts = read_file(path_tslt)\n",
    "        refs_tok = [[wordpunct_tokenize(sentence)] for sentence in refs]\n",
    "        tslts_tok = [wordpunct_tokenize(sentence) for sentence in tslts]\n",
    "\n",
    "        bleu_scores_sentence_lv = []\n",
    "        for i in range(len(refs_tok)):\n",
    "            refi = refs_tok[i]\n",
    "            tslti = tslts_tok[i]\n",
    "            bleu_scores_sentence_lv.append(sentence_bleu(refi, tslti))\n",
    "        avg_bleu_scores_sentence_lv = sum(bleu_scores_sentence_lv)/len(bleu_scores_sentence_lv)\n",
    "\n",
    "        # print(bleu_scores_sentence_lv)\n",
    "\n",
    "        print(\"%s|gpt-3.5-turbo|TP%d|sentence_bleu_avg = \"%(src_name,tpi))\n",
    "        print(avg_bleu_scores_sentence_lv)\n",
    "\n",
    "    for tslt_name in list_tslt_folder:\n",
    "        path_tslt = 'translated/'+tslt_name+'_API/'+tslt_name+'_'+src_name+'_tslt_en.txt'\n",
    "\n",
    "        refs = read_file(path_ref)\n",
    "        tslts = read_file(path_tslt)\n",
    "        refs_tok = [[wordpunct_tokenize(sentence)] for sentence in refs]\n",
    "        tslts_tok = [wordpunct_tokenize(sentence) for sentence in tslts]\n",
    "\n",
    "        bleu_scores_sentence_lv = []\n",
    "        for i in range(len(refs_tok)):\n",
    "            refi = refs_tok[i]\n",
    "            tslti = tslts_tok[i]\n",
    "            bleu_scores_sentence_lv.append(sentence_bleu(refi, tslti))\n",
    "        avg_bleu_scores_sentence_lv = sum(bleu_scores_sentence_lv)/len(bleu_scores_sentence_lv)\n",
    "\n",
    "        print(\"%s|%s|sentence_bleu_avg = \"%(src_name,tslt_name))\n",
    "        print(avg_bleu_scores_sentence_lv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bert_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert_score sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000]) tensor([1.0000, 1.0000]) tensor([1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# sentence-lv bert_score sample\n",
    "from bert_score import score\n",
    "\n",
    "cands = ['this is 1', 'this is 2']\n",
    "refs = ['this is 1', 'this is 2']\n",
    "P, R, F1 = score(cands, refs, lang='en')\n",
    "print(P, R, F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert_score evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh.source1.CL_SA450|gpt-3.5-turbo|TP1|avg_bert_score[P, R, F1] = \n",
      "[0.9393912553787231, 0.9397478699684143, 0.9394848346710205]\n",
      "zh.source1.CL_SA450|gpt-3.5-turbo|TP2|avg_bert_score[P, R, F1] = \n",
      "[0.9365745782852173, 0.9371306300163269, 0.9367662072181702]\n",
      "zh.source1.CL_SA450|gpt-3.5-turbo|TP3|avg_bert_score[P, R, F1] = \n",
      "[0.9392860531806946, 0.9406151175498962, 0.9398643374443054]\n",
      "zh.source1.CL_SA450|NLLB|avg_bert_score[P, R, F1] = \n",
      "[0.9275792241096497, 0.9262470602989197, 0.926801323890686]\n",
      "zh.source1.CL_SA450|Google|avg_bert_score[P, R, F1] = \n",
      "[0.9474057555198669, 0.9438767433166504, 0.9455528259277344]\n",
      "zh.source1.CL_SA450|DeepL|avg_bert_score[P, R, F1] = \n",
      "[0.9357784986495972, 0.9346756935119629, 0.9351478219032288]\n",
      "zh.source2.CT-SA350|gpt-3.5-turbo|TP1|avg_bert_score[P, R, F1] = \n",
      "[0.9421859383583069, 0.9430044889450073, 0.9425522089004517]\n",
      "zh.source2.CT-SA350|gpt-3.5-turbo|TP2|avg_bert_score[P, R, F1] = \n",
      "[0.9436308741569519, 0.9423050284385681, 0.9429275989532471]\n",
      "zh.source2.CT-SA350|gpt-3.5-turbo|TP3|avg_bert_score[P, R, F1] = \n",
      "[0.9428592324256897, 0.9433711171150208, 0.943073570728302]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh.source2.CT-SA350|NLLB|avg_bert_score[P, R, F1] = \n",
      "[0.9290854930877686, 0.9263474941253662, 0.9276657700538635]\n",
      "zh.source2.CT-SA350|Google|avg_bert_score[P, R, F1] = \n",
      "[0.9500586986541748, 0.9480114579200745, 0.9489890933036804]\n",
      "zh.source2.CT-SA350|DeepL|avg_bert_score[P, R, F1] = \n",
      "[0.9422419667243958, 0.9417366981506348, 0.9419476389884949]\n",
      "zh.source3.LA400|gpt-3.5-turbo|TP1|avg_bert_score[P, R, F1] = \n",
      "[0.950654149055481, 0.9514222741127014, 0.9509723782539368]\n",
      "zh.source3.LA400|gpt-3.5-turbo|TP2|avg_bert_score[P, R, F1] = \n",
      "[0.9507081508636475, 0.9503522515296936, 0.9504678249359131]\n",
      "zh.source3.LA400|gpt-3.5-turbo|TP3|avg_bert_score[P, R, F1] = \n",
      "[0.9511091113090515, 0.9513288736343384, 0.9511555433273315]\n",
      "zh.source3.LA400|NLLB|avg_bert_score[P, R, F1] = \n",
      "[0.9368485808372498, 0.9347572326660156, 0.9357397556304932]\n",
      "zh.source3.LA400|Google|avg_bert_score[P, R, F1] = \n",
      "[0.9543501138687134, 0.9517157077789307, 0.9529737830162048]\n",
      "zh.source3.LA400|DeepL|avg_bert_score[P, R, F1] = \n",
      "[0.9450541734695435, 0.9441332817077637, 0.9445381164550781]\n",
      "zh.source|gpt-3.5-turbo|TP1|avg_bert_score[P, R, F1] = \n",
      "[0.9439606666564941, 0.9445891380310059, 0.9442086815834045]\n",
      "zh.source|gpt-3.5-turbo|TP2|avg_bert_score[P, R, F1] = \n",
      "[0.9433438181877136, 0.9430471062660217, 0.9431304931640625]\n",
      "zh.source|gpt-3.5-turbo|TP3|avg_bert_score[P, R, F1] = \n",
      "[0.9442692995071411, 0.9449902176856995, 0.9445641040802002]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh.source|NLLB|avg_bert_score[P, R, F1] = \n",
      "[0.931108295917511, 0.9291131496429443, 0.9300329685211182]\n",
      "zh.source|Google|avg_bert_score[P, R, F1] = \n",
      "[0.9504942893981934, 0.9476957321166992, 0.949028730392456]\n",
      "zh.source|DeepL|avg_bert_score[P, R, F1] = \n",
      "[0.9407556056976318, 0.9398877024650574, 0.9402612447738647]\n"
     ]
    }
   ],
   "source": [
    "list_src_name = ['zh.source1.CL_SA450', 'zh.source2.CT-SA350', 'zh.source3.LA400', 'zh.source']\n",
    "list_ref_name = ['test.true.en1.CL_SA450', 'test.true.en2.CT-SA350', 'test.true.en3.LA400', 'test.true.en']\n",
    "# GPT individual\n",
    "list_tslt_folder = ['NLLB', 'Google', 'DeepL']\n",
    "\n",
    "import logging\n",
    "from bert_score import score as bert_score\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [line.strip() for line in lines]\n",
    "\n",
    "# Suppress warnings from transformers\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "for i_name in range(len(list_src_name)):\n",
    "    src_name = list_src_name[i_name]\n",
    "    ref_name = list_ref_name[i_name]\n",
    "\n",
    "    path_ref = 'dataset/'+ref_name\n",
    "    for tpi in range(1,3+1):\n",
    "        id_src = \"\"\n",
    "        if i_name != 3:\n",
    "            id_src = str(i_name+1)\n",
    "        path_tslt = 'translated/gpt-3.5-turbo_API/zh.source'+id_src+'_tp'+str(tpi)+'_tslt_en.txt'\n",
    "\n",
    "        refs = read_file(path_ref)\n",
    "        tslts = read_file(path_tslt)\n",
    "\n",
    "        P, R, F1 = bert_score(tslts, refs, lang='en', device=device)\n",
    "        avg_bert_score_P_R_F1=[P.mean().item(), R.mean().item(), F1.mean().item()]\n",
    "        print(\"%s|gpt-3.5-turbo|TP%d|avg_bert_score[P, R, F1] = \"%(src_name,tpi))\n",
    "        print(avg_bert_score_P_R_F1)\n",
    "\n",
    "    for tslt_name in list_tslt_folder:\n",
    "        path_tslt = 'translated/'+tslt_name+'_API/'+tslt_name+'_'+src_name+'_tslt_en.txt'\n",
    "\n",
    "        refs = read_file(path_ref)\n",
    "        tslts = read_file(path_tslt)\n",
    "\n",
    "        P, R, F1 = bert_score(tslts, refs, lang='en', device=device)\n",
    "        avg_bert_score_P_R_F1=[P.mean().item(), R.mean().item(), F1.mean().item()]\n",
    "        print(\"%s|%s|avg_bert_score[P, R, F1] = \"%(src_name,tslt_name))\n",
    "        print(avg_bert_score_P_R_F1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bleurt_score\n",
    "- intall: https://github.com/google-research/bleurt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bleurt_score sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7463240027427673\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from bleurt import score as bleurt_score\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "checkpoint = \"bleurt/test_checkpoint\"\n",
    "\n",
    "references = [\"This is a test.\"]\n",
    "candidates = [\"This is the test.\"]\n",
    "\n",
    "bleurt_scorer = bleurt_score.BleurtScorer()\n",
    "bleurt_scores = bleurt_scorer.score(references=references, candidates=candidates)[0]\n",
    "# assert isinstance(scores, list) and len(scores) == 1\n",
    "print(bleurt_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bleurt_score evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh.source1.CL_SA450|gpt-3.5-turbo|TP1|avg_bleurt_score = \n",
      "0.4034105663994948\n",
      "zh.source1.CL_SA450|gpt-3.5-turbo|TP2|avg_bleurt_score = \n",
      "0.39062041670084\n",
      "zh.source1.CL_SA450|gpt-3.5-turbo|TP3|avg_bleurt_score = \n",
      "0.40343021182550326\n",
      "zh.source1.CL_SA450|NLLB|sentence_bleu_avg = \n",
      "0.24216023335854212\n",
      "zh.source1.CL_SA450|Google|sentence_bleu_avg = \n",
      "0.40325494291053876\n",
      "zh.source1.CL_SA450|DeepL|sentence_bleu_avg = \n",
      "0.3409347960518466\n",
      "zh.source2.CT-SA350|gpt-3.5-turbo|TP1|avg_bleurt_score = \n",
      "0.41219661135758673\n",
      "zh.source2.CT-SA350|gpt-3.5-turbo|TP2|avg_bleurt_score = \n",
      "0.4045568690129689\n",
      "zh.source2.CT-SA350|gpt-3.5-turbo|TP3|avg_bleurt_score = \n",
      "0.415498162571873\n",
      "zh.source2.CT-SA350|NLLB|sentence_bleu_avg = \n",
      "0.21882923743554525\n",
      "zh.source2.CT-SA350|Google|sentence_bleu_avg = \n",
      "0.4421633297630719\n",
      "zh.source2.CT-SA350|DeepL|sentence_bleu_avg = \n",
      "0.37189702380980766\n",
      "zh.source3.LA400|gpt-3.5-turbo|TP1|avg_bleurt_score = \n",
      "0.29131466342136264\n",
      "zh.source3.LA400|gpt-3.5-turbo|TP2|avg_bleurt_score = \n",
      "0.2923653990030289\n",
      "zh.source3.LA400|gpt-3.5-turbo|TP3|avg_bleurt_score = \n",
      "0.29105295553803445\n",
      "zh.source3.LA400|NLLB|sentence_bleu_avg = \n",
      "0.004091806877404451\n",
      "zh.source3.LA400|Google|sentence_bleu_avg = \n",
      "0.2846433518826961\n",
      "zh.source3.LA400|DeepL|sentence_bleu_avg = \n",
      "0.1373954585380852\n",
      "zh.source|gpt-3.5-turbo|TP1|avg_bleurt_score = \n",
      "0.36860786185289424\n",
      "zh.source|gpt-3.5-turbo|TP2|avg_bleurt_score = \n",
      "0.3619335427259405\n",
      "zh.source|gpt-3.5-turbo|TP3|avg_bleurt_score = \n",
      "0.36949094536403815\n",
      "zh.source|NLLB|sentence_bleu_avg = \n",
      "0.1559992173872888\n",
      "zh.source|Google|sentence_bleu_avg = \n",
      "0.3750660253999134\n",
      "zh.source|DeepL|sentence_bleu_avg = \n",
      "0.2821189999766648\n"
     ]
    }
   ],
   "source": [
    "list_src_name = ['zh.source1.CL_SA450', 'zh.source2.CT-SA350', 'zh.source3.LA400', 'zh.source']\n",
    "list_ref_name = ['test.true.en1.CL_SA450', 'test.true.en2.CT-SA350', 'test.true.en3.LA400', 'test.true.en']\n",
    "# GPT individual\n",
    "list_tslt_folder = ['NLLB', 'Google', 'DeepL']\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from bleurt import score as bleurt_score\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "checkpoint = \"bleurt/test_checkpoint\"\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [line.strip() for line in lines]\n",
    "\n",
    "bleurt_scorer = bleurt_score.BleurtScorer()\n",
    "\n",
    "for i_name in range(len(list_src_name)):\n",
    "    src_name = list_src_name[i_name]\n",
    "    ref_name = list_ref_name[i_name]\n",
    "\n",
    "    path_ref = 'dataset/'+ref_name\n",
    "    for tpi in range(1,3+1):\n",
    "        id_src = \"\"\n",
    "        if i_name != 3:\n",
    "            id_src = str(i_name+1)\n",
    "        path_tslt = 'translated/gpt-3.5-turbo_API/zh.source'+id_src+'_tp'+str(tpi)+'_tslt_en.txt'\n",
    "\n",
    "        refs = read_file(path_ref)\n",
    "        tslts = read_file(path_tslt)\n",
    "\n",
    "        bleurt_scores = [bleurt_scorer.score(references=[r], candidates=[t])[0] for r,t in zip(refs, tslts)]\n",
    "        avg_bleurt_score = sum(bleurt_scores)/len(bleurt_scores)\n",
    "\n",
    "        print(\"%s|gpt-3.5-turbo|TP%d|avg_bleurt_score = \"%(src_name,tpi))\n",
    "        print(avg_bleurt_score)\n",
    "\n",
    "    for tslt_name in list_tslt_folder:\n",
    "        path_tslt = 'translated/'+tslt_name+'_API/'+tslt_name+'_'+src_name+'_tslt_en.txt'\n",
    "\n",
    "        refs = read_file(path_ref)\n",
    "        tslts = read_file(path_tslt)\n",
    "\n",
    "        bleurt_scores = [bleurt_scorer.score(references=[r], candidates=[t])[0] for r,t in zip(refs, tslts)]\n",
    "        avg_bleurt_score = sum(bleurt_scores)/len(bleurt_scores)\n",
    "\n",
    "        print(\"%s|%s|sentence_bleu_avg = \"%(src_name,tslt_name))\n",
    "        print(avg_bleurt_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity-Aware BERTScore + Commonsense Reasoning Accuracy\n",
    "- https://github.com/YutongWang1216/CR-NMT\n",
    "\n",
    "conda activate ev4nlpCr2\n",
    "cd D:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project\\CR-NMT-main\n",
    "\n",
    "python ent_bertscore/ent_score.py     --candidate data/ptnmt/cr-test.hyp     --r_reference data/cr_testset/test.true.en     --c_reference data/cr_testset/test.wrong.en     --weight 1.4     --outdir example/\n",
    "\n",
    "python CR_accuracy/calculate_accuracy.py     --r_score example/true.score.bert_1.4     --c_score example/wrong.score.bert_1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate cmd code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = ['conda activate ev4nlpCr2',\n",
    "'cd D:/BaidNetdiskSync_CXH/nlp2ct_cr_project/CR-NMT-main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh.source|gpt-3.5-turbo|TP1|cmd1:\n",
      "python ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/gpt-3.5-turbo_API/zh.source_tp1_tslt_en.txt         --weight 1.4         --outdir model/zh.source_gpt-3.5-turbo_tp1/\n",
      "\n",
      "zh.source|gpt-3.5-turbo|TP1|cmd2:\n",
      "python CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_gpt-3.5-turbo_tp1/true.score.bert_1.4         --c_score model/zh.source_gpt-3.5-turbo_tp1/wrong.score.bert_1.4 >> cmd_output.txt\n",
      "\n",
      "-----\n",
      "\n",
      "zh.source|gpt-3.5-turbo|TP2|cmd1:\n",
      "python ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/gpt-3.5-turbo_API/zh.source_tp2_tslt_en.txt         --weight 1.4         --outdir model/zh.source_gpt-3.5-turbo_tp2/\n",
      "\n",
      "zh.source|gpt-3.5-turbo|TP2|cmd2:\n",
      "python CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_gpt-3.5-turbo_tp2/true.score.bert_1.4         --c_score model/zh.source_gpt-3.5-turbo_tp2/wrong.score.bert_1.4 >> cmd_output.txt\n",
      "\n",
      "-----\n",
      "\n",
      "zh.source|gpt-3.5-turbo|TP3|cmd1:\n",
      "python ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/gpt-3.5-turbo_API/zh.source_tp3_tslt_en.txt         --weight 1.4         --outdir model/zh.source_gpt-3.5-turbo_tp3/\n",
      "\n",
      "zh.source|gpt-3.5-turbo|TP3|cmd2:\n",
      "python CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_gpt-3.5-turbo_tp3/true.score.bert_1.4         --c_score model/zh.source_gpt-3.5-turbo_tp3/wrong.score.bert_1.4 >> cmd_output.txt\n",
      "\n",
      "-----\n",
      "\n",
      "zh.source|NLLB|cmd1 = \n",
      "python ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/NLLB_API/NLLB_zh.source_tslt_en.txt         --weight 1.4         --outdir model/zh.source_NLLB/\n",
      "\n",
      "zh.source|NLLB|cmd2 = \n",
      "python CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_NLLB/true.score.bert_1.4         --c_score model/zh.source_NLLB/wrong.score.bert_1.4 >> cmd_output.txt\n",
      "\n",
      "-----\n",
      "\n",
      "zh.source|Google|cmd1 = \n",
      "python ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/Google_API/Google_zh.source_tslt_en.txt         --weight 1.4         --outdir model/zh.source_Google/\n",
      "\n",
      "zh.source|Google|cmd2 = \n",
      "python CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_Google/true.score.bert_1.4         --c_score model/zh.source_Google/wrong.score.bert_1.4 >> cmd_output.txt\n",
      "\n",
      "-----\n",
      "\n",
      "zh.source|DeepL|cmd1 = \n",
      "python ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/DeepL_API/DeepL_zh.source_tslt_en.txt         --weight 1.4         --outdir model/zh.source_DeepL/\n",
      "\n",
      "zh.source|DeepL|cmd2 = \n",
      "python CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_DeepL/true.score.bert_1.4         --c_score model/zh.source_DeepL/wrong.score.bert_1.4 >> cmd_output.txt\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_src_name = ['zh.source']\n",
    "list_ref_name = ['test.true.en']\n",
    "# GPT individual\n",
    "list_tslt_folder = ['NLLB', 'Google', 'DeepL']\n",
    "\n",
    "for i_name in range(len(list_src_name)):\n",
    "    src_name = list_src_name[i_name]\n",
    "    ref_name = list_ref_name[i_name]\n",
    "\n",
    "    path_ref = '../dataset/'+ref_name\n",
    "    path_candhyp = '../candidate_hyp/'+ref_name+'.hyp'\n",
    "    for tpi in range(1,3+1):\n",
    "        id_src = \"\"\n",
    "        # if i_name != 3:\n",
    "        #     id_src = str(i_name+1)\n",
    "        path_tslt = '../translated/gpt-3.5-turbo_API/zh.source'+id_src+'_tp'+str(tpi)+'_tslt_en.txt'\n",
    "\n",
    "        path_outdir = 'model/'+src_name+'_gpt-3.5-turbo_tp'+str(tpi)\n",
    "\n",
    "        cmd1 = \"\"\"python ent_bertscore/ent_score.py \\\n",
    "        --candidate data/ptnmt/cr-test.hyp \\\n",
    "        --r_reference %s \\\n",
    "        --c_reference %s \\\n",
    "        --weight 1.4 \\\n",
    "        --outdir %s/\"\"\"%(path_ref, path_tslt, path_outdir)\n",
    "        cmd1=cmd1.replace('\\n',' ')\n",
    "        print(\"%s|gpt-3.5-turbo|TP%d|cmd1:\"%(src_name,tpi))\n",
    "        print(cmd1+'\\n')\n",
    "        commands.append(cmd1.strip())\n",
    "\n",
    "        cmd2 = \"\"\"python CR_accuracy/calculate_accuracy.py \\\n",
    "        --r_score %s/true.score.bert_1.4 \\\n",
    "        --c_score %s/wrong.score.bert_1.4\"\"\"%(path_outdir, path_outdir)\n",
    "        cmd2+=' >> cmd_output.txt'\n",
    "        print(\"%s|gpt-3.5-turbo|TP%d|cmd2:\"%(src_name,tpi))\n",
    "        print(cmd2+'\\n\\n-----\\n')\n",
    "        commands.append(cmd2.strip())\n",
    "\n",
    "    for tslt_name in list_tslt_folder:\n",
    "        path_tslt = '../translated/'+tslt_name+'_API/'+tslt_name+'_'+src_name+'_tslt_en.txt'\n",
    "        path_outdir = 'model/'+src_name+'_'+tslt_name\n",
    "    \n",
    "        cmd1 = \"\"\"python ent_bertscore/ent_score.py \\\n",
    "        --candidate data/ptnmt/cr-test.hyp \\\n",
    "        --r_reference %s \\\n",
    "        --c_reference %s \\\n",
    "        --weight 1.4 \\\n",
    "        --outdir %s/\"\"\"%(path_ref, path_tslt, path_outdir)\n",
    "        cmd1=cmd1.replace('\\n',' ')\n",
    "        print(\"%s|%s|cmd1 = \"%(src_name,tslt_name))\n",
    "        print(cmd1+'\\n')\n",
    "        commands.append(cmd1.strip())\n",
    "\n",
    "        cmd2 = \"\"\"python CR_accuracy/calculate_accuracy.py \\\n",
    "        --r_score %s/true.score.bert_1.4 \\\n",
    "        --c_score %s/wrong.score.bert_1.4\"\"\"%(path_outdir, path_outdir)\n",
    "        cmd2+=' >> cmd_output.txt'\n",
    "        print(\"%s|%s|cmd2 = \"%(src_name,tslt_name))\n",
    "        print(cmd2+'\\n\\n-----\\n')\n",
    "        commands.append(cmd2.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conda activate ev4nlpCr2\\ncd D:/BaidNetdiskSync_CXH/nlp2ct_cr_project/CR-NMT-main\\npython ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/gpt-3.5-turbo_API/zh.source_tp1_tslt_en.txt         --weight 1.4         --outdir model/zh.source_gpt-3.5-turbo_tp1/\\npython CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_gpt-3.5-turbo_tp1/true.score.bert_1.4         --c_score model/zh.source_gpt-3.5-turbo_tp1/wrong.score.bert_1.4 >> cmd_output.txt\\npython ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/gpt-3.5-turbo_API/zh.source_tp2_tslt_en.txt         --weight 1.4         --outdir model/zh.source_gpt-3.5-turbo_tp2/\\npython CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_gpt-3.5-turbo_tp2/true.score.bert_1.4         --c_score model/zh.source_gpt-3.5-turbo_tp2/wrong.score.bert_1.4 >> cmd_output.txt\\npython ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/gpt-3.5-turbo_API/zh.source_tp3_tslt_en.txt         --weight 1.4         --outdir model/zh.source_gpt-3.5-turbo_tp3/\\npython CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_gpt-3.5-turbo_tp3/true.score.bert_1.4         --c_score model/zh.source_gpt-3.5-turbo_tp3/wrong.score.bert_1.4 >> cmd_output.txt\\npython ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/NLLB_API/NLLB_zh.source_tslt_en.txt         --weight 1.4         --outdir model/zh.source_NLLB/\\npython CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_NLLB/true.score.bert_1.4         --c_score model/zh.source_NLLB/wrong.score.bert_1.4 >> cmd_output.txt\\npython ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/Google_API/Google_zh.source_tslt_en.txt         --weight 1.4         --outdir model/zh.source_Google/\\npython CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_Google/true.score.bert_1.4         --c_score model/zh.source_Google/wrong.score.bert_1.4 >> cmd_output.txt\\npython ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/DeepL_API/DeepL_zh.source_tslt_en.txt         --weight 1.4         --outdir model/zh.source_DeepL/\\npython CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_DeepL/true.score.bert_1.4         --c_score model/zh.source_DeepL/wrong.score.bert_1.4 >> cmd_output.txt\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commands = '\\n'.join(commands)+'\\n'\n",
    "commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.22621.2861]\n",
      "(c) Microsoft Corporation. All rights reserved.\n",
      "\n",
      "(base) d:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project>conda activate ev4nlpCr2\n",
      "\n",
      "(ev4nlpCr2) d:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project>cd D:/BaidNetdiskSync_CXH/nlp2ct_cr_project/CR-NMT-main\n",
      "\n",
      "(ev4nlpCr2) D:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project\\CR-NMT-main>python ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/gpt-3.5-turbo_API/zh.source_tp1_tslt_en.txt         --weight 1.4         --outdir model/zh.source_gpt-3.5-turbo_tp1/\n",
      "Current weight of commonsense entities: 1.40\n",
      "calculating scores...\n",
      "computing bert embedding.\n",
      "computing greedy matching.\n",
      "done in 3.86 seconds, 310.89 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n",
      "computing greedy matching.\n",
      "done in 3.42 seconds, 351.13 sentences/sec\n",
      "\n",
      "(ev4nlpCr2) D:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project\\CR-NMT-main>python CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_gpt-3.5-turbo_tp1/true.score.bert_1.4         --c_score model/zh.source_gpt-3.5-turbo_tp1/wrong.score.bert_1.4 >> cmd_output.txt\n",
      "\n",
      "(ev4nlpCr2) D:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project\\CR-NMT-main>python ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/gpt-3.5-turbo_API/zh.source_tp2_tslt_en.txt         --weight 1.4         --outdir model/zh.source_gpt-3.5-turbo_tp2/\n",
      "Current weight of commonsense entities: 1.40\n",
      "calculating scores...\n",
      "computing bert embedding.\n",
      "computing greedy matching.\n",
      "done in 4.01 seconds, 299.11 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n",
      "computing greedy matching.\n",
      "done in 3.51 seconds, 341.89 sentences/sec\n",
      "\n",
      "(ev4nlpCr2) D:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project\\CR-NMT-main>python CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_gpt-3.5-turbo_tp2/true.score.bert_1.4         --c_score model/zh.source_gpt-3.5-turbo_tp2/wrong.score.bert_1.4 >> cmd_output.txt\n",
      "\n",
      "(ev4nlpCr2) D:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project\\CR-NMT-main>python ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/gpt-3.5-turbo_API/zh.source_tp3_tslt_en.txt         --weight 1.4         --outdir model/zh.source_gpt-3.5-turbo_tp3/\n",
      "Current weight of commonsense entities: 1.40\n",
      "calculating scores...\n",
      "computing bert embedding.\n",
      "computing greedy matching.\n",
      "done in 4.00 seconds, 299.82 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n",
      "computing greedy matching.\n",
      "done in 3.47 seconds, 346.06 sentences/sec\n",
      "\n",
      "(ev4nlpCr2) D:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project\\CR-NMT-main>python CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_gpt-3.5-turbo_tp3/true.score.bert_1.4         --c_score model/zh.source_gpt-3.5-turbo_tp3/wrong.score.bert_1.4 >> cmd_output.txt\n",
      "\n",
      "(ev4nlpCr2) D:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project\\CR-NMT-main>python ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/NLLB_API/NLLB_zh.source_tslt_en.txt         --weight 1.4         --outdir model/zh.source_NLLB/\n",
      "Current weight of commonsense entities: 1.40\n",
      "calculating scores...\n",
      "computing bert embedding.\n",
      "computing greedy matching.\n",
      "done in 3.78 seconds, 317.50 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n",
      "computing greedy matching.\n",
      "done in 3.21 seconds, 374.31 sentences/sec\n",
      "\n",
      "(ev4nlpCr2) D:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project\\CR-NMT-main>python CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_NLLB/true.score.bert_1.4         --c_score model/zh.source_NLLB/wrong.score.bert_1.4 >> cmd_output.txt\n",
      "\n",
      "(ev4nlpCr2) D:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project\\CR-NMT-main>python ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/Google_API/Google_zh.source_tslt_en.txt         --weight 1.4         --outdir model/zh.source_Google/\n",
      "Current weight of commonsense entities: 1.40\n",
      "calculating scores...\n",
      "computing bert embedding.\n",
      "computing greedy matching.\n",
      "done in 3.68 seconds, 325.66 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n",
      "computing greedy matching.\n",
      "done in 3.80 seconds, 316.13 sentences/sec\n",
      "\n",
      "(ev4nlpCr2) D:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project\\CR-NMT-main>python CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_Google/true.score.bert_1.4         --c_score model/zh.source_Google/wrong.score.bert_1.4 >> cmd_output.txt\n",
      "\n",
      "(ev4nlpCr2) D:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project\\CR-NMT-main>python ent_bertscore/ent_score.py         --candidate data/ptnmt/cr-test.hyp         --r_reference ../dataset/test.true.en         --c_reference ../translated/DeepL_API/DeepL_zh.source_tslt_en.txt         --weight 1.4         --outdir model/zh.source_DeepL/\n",
      "Current weight of commonsense entities: 1.40\n",
      "calculating scores...\n",
      "computing bert embedding.\n",
      "computing greedy matching.\n",
      "done in 3.63 seconds, 330.64 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n",
      "computing greedy matching.\n",
      "done in 3.15 seconds, 380.95 sentences/sec\n",
      "\n",
      "(ev4nlpCr2) D:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project\\CR-NMT-main>python CR_accuracy/calculate_accuracy.py         --r_score model/zh.source_DeepL/true.score.bert_1.4         --c_score model/zh.source_DeepL/wrong.score.bert_1.4 >> cmd_output.txt\n",
      "\n",
      "(ev4nlpCr2) D:\\BaidNetdiskSync_CXH\\nlp2ct_cr_project\\CR-NMT-main>\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]\n",
      "  3%|▎         | 1/37 [00:00<00:19,  1.84it/s]\n",
      "  5%|▌         | 2/37 [00:00<00:10,  3.18it/s]\n",
      "  8%|▊         | 3/37 [00:00<00:07,  4.36it/s]\n",
      " 11%|█         | 4/37 [00:00<00:06,  5.07it/s]\n",
      " 14%|█▎        | 5/37 [00:01<00:05,  5.89it/s]\n",
      " 19%|█▉        | 7/37 [00:01<00:04,  7.19it/s]\n",
      " 24%|██▍       | 9/37 [00:01<00:03,  8.07it/s]\n",
      " 30%|██▉       | 11/37 [00:01<00:03,  8.58it/s]\n",
      " 32%|███▏      | 12/37 [00:01<00:02,  8.79it/s]\n",
      " 38%|███▊      | 14/37 [00:02<00:02,  9.08it/s]\n",
      " 43%|████▎     | 16/37 [00:02<00:02,  9.60it/s]\n",
      " 49%|████▊     | 18/37 [00:02<00:01, 10.30it/s]\n",
      " 54%|█████▍    | 20/37 [00:02<00:01, 10.71it/s]\n",
      " 59%|█████▉    | 22/37 [00:02<00:01, 10.93it/s]\n",
      " 65%|██████▍   | 24/37 [00:02<00:01, 11.77it/s]\n",
      " 70%|███████   | 26/37 [00:03<00:00, 12.42it/s]\n",
      " 76%|███████▌  | 28/37 [00:03<00:00, 13.32it/s]\n",
      " 81%|████████  | 30/37 [00:03<00:00, 14.20it/s]\n",
      " 86%|████████▋ | 32/37 [00:03<00:00, 14.54it/s]\n",
      " 92%|█████████▏| 34/37 [00:03<00:00, 15.22it/s]\n",
      " 97%|█████████▋| 36/37 [00:03<00:00, 15.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 10.13it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 47%|████▋     | 9/19 [00:00<00:00, 89.11it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 93.32it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 92.70it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]\n",
      "  3%|▎         | 1/37 [00:00<00:06,  5.37it/s]\n",
      "  5%|▌         | 2/37 [00:00<00:05,  6.47it/s]\n",
      "  8%|▊         | 3/37 [00:00<00:04,  7.27it/s]\n",
      " 11%|█         | 4/37 [00:00<00:04,  7.39it/s]\n",
      " 14%|█▎        | 5/37 [00:00<00:04,  7.81it/s]\n",
      " 16%|█▌        | 6/37 [00:00<00:03,  8.07it/s]\n",
      " 19%|█▉        | 7/37 [00:00<00:03,  8.11it/s]\n",
      " 22%|██▏       | 8/37 [00:01<00:03,  8.51it/s]\n",
      " 24%|██▍       | 9/37 [00:01<00:03,  8.69it/s]\n",
      " 27%|██▋       | 10/37 [00:01<00:02,  9.02it/s]\n",
      " 30%|██▉       | 11/37 [00:01<00:02,  9.23it/s]\n",
      " 35%|███▌      | 13/37 [00:01<00:02,  9.53it/s]\n",
      " 41%|████      | 15/37 [00:01<00:02, 10.02it/s]\n",
      " 46%|████▌     | 17/37 [00:01<00:01, 10.11it/s]\n",
      " 51%|█████▏    | 19/37 [00:02<00:01, 10.79it/s]\n",
      " 57%|█████▋    | 21/37 [00:02<00:01, 10.86it/s]\n",
      " 62%|██████▏   | 23/37 [00:02<00:01, 11.65it/s]\n",
      " 68%|██████▊   | 25/37 [00:02<00:00, 12.29it/s]\n",
      " 73%|███████▎  | 27/37 [00:02<00:00, 13.31it/s]\n",
      " 78%|███████▊  | 29/37 [00:02<00:00, 14.13it/s]\n",
      " 84%|████████▍ | 31/37 [00:02<00:00, 14.65it/s]\n",
      " 89%|████████▉ | 33/37 [00:03<00:00, 15.24it/s]\n",
      " 95%|█████████▍| 35/37 [00:03<00:00, 15.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.46it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 53%|█████▎    | 10/19 [00:00<00:00, 96.07it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 102.23it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]\n",
      "  3%|▎         | 1/37 [00:00<00:20,  1.76it/s]\n",
      "  5%|▌         | 2/37 [00:00<00:11,  3.08it/s]\n",
      "  8%|▊         | 3/37 [00:00<00:08,  4.13it/s]\n",
      " 11%|█         | 4/37 [00:01<00:06,  4.99it/s]\n",
      " 14%|█▎        | 5/37 [00:01<00:05,  5.70it/s]\n",
      " 16%|█▌        | 6/37 [00:01<00:04,  6.27it/s]\n",
      " 19%|█▉        | 7/37 [00:01<00:04,  6.87it/s]\n",
      " 22%|██▏       | 8/37 [00:01<00:03,  7.26it/s]\n",
      " 24%|██▍       | 9/37 [00:01<00:03,  7.50it/s]\n",
      " 27%|██▋       | 10/37 [00:01<00:03,  8.01it/s]\n",
      " 30%|██▉       | 11/37 [00:01<00:03,  8.33it/s]\n",
      " 32%|███▏      | 12/37 [00:01<00:02,  8.75it/s]\n",
      " 35%|███▌      | 13/37 [00:02<00:02,  9.04it/s]\n",
      " 38%|███▊      | 14/37 [00:02<00:02,  9.04it/s]\n",
      " 43%|████▎     | 16/37 [00:02<00:02,  9.98it/s]\n",
      " 46%|████▌     | 17/37 [00:02<00:02,  9.92it/s]\n",
      " 51%|█████▏    | 19/37 [00:02<00:01, 10.90it/s]\n",
      " 57%|█████▋    | 21/37 [00:02<00:01, 10.80it/s]\n",
      " 62%|██████▏   | 23/37 [00:02<00:01, 11.58it/s]\n",
      " 68%|██████▊   | 25/37 [00:03<00:00, 12.03it/s]\n",
      " 73%|███████▎  | 27/37 [00:03<00:00, 12.71it/s]\n",
      " 78%|███████▊  | 29/37 [00:03<00:00, 13.40it/s]\n",
      " 84%|████████▍ | 31/37 [00:03<00:00, 14.16it/s]\n",
      " 89%|████████▉ | 33/37 [00:03<00:00, 14.81it/s]\n",
      " 95%|█████████▍| 35/37 [00:03<00:00, 15.33it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00,  9.77it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 47%|████▋     | 9/19 [00:00<00:00, 87.91it/s]\n",
      " 95%|█████████▍| 18/19 [00:00<00:00, 83.33it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 85.85it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]\n",
      "  3%|▎         | 1/37 [00:00<00:06,  5.47it/s]\n",
      "  5%|▌         | 2/37 [00:00<00:05,  6.39it/s]\n",
      "  8%|▊         | 3/37 [00:00<00:05,  6.65it/s]\n",
      " 11%|█         | 4/37 [00:00<00:04,  6.96it/s]\n",
      " 14%|█▎        | 5/37 [00:00<00:04,  7.35it/s]\n",
      " 16%|█▌        | 6/37 [00:00<00:04,  7.33it/s]\n",
      " 19%|█▉        | 7/37 [00:00<00:03,  7.62it/s]\n",
      " 22%|██▏       | 8/37 [00:01<00:03,  7.70it/s]\n",
      " 27%|██▋       | 10/37 [00:01<00:03,  8.51it/s]\n",
      " 30%|██▉       | 11/37 [00:01<00:02,  8.71it/s]\n",
      " 32%|███▏      | 12/37 [00:01<00:02,  8.85it/s]\n",
      " 38%|███▊      | 14/37 [00:01<00:02,  9.57it/s]\n",
      " 43%|████▎     | 16/37 [00:01<00:02,  9.90it/s]\n",
      " 46%|████▌     | 17/37 [00:02<00:02,  9.84it/s]\n",
      " 51%|█████▏    | 19/37 [00:02<00:01, 10.43it/s]\n",
      " 57%|█████▋    | 21/37 [00:02<00:01, 10.40it/s]\n",
      " 62%|██████▏   | 23/37 [00:02<00:01, 11.29it/s]\n",
      " 68%|██████▊   | 25/37 [00:02<00:01, 11.97it/s]\n",
      " 73%|███████▎  | 27/37 [00:02<00:00, 12.96it/s]\n",
      " 78%|███████▊  | 29/37 [00:02<00:00, 13.89it/s]\n",
      " 84%|████████▍ | 31/37 [00:03<00:00, 15.05it/s]\n",
      " 89%|████████▉ | 33/37 [00:03<00:00, 15.36it/s]\n",
      " 95%|█████████▍| 35/37 [00:03<00:00, 16.06it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.13it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 53%|█████▎    | 10/19 [00:00<00:00, 91.79it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 103.26it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]\n",
      "  3%|▎         | 1/37 [00:00<00:21,  1.71it/s]\n",
      "  5%|▌         | 2/37 [00:00<00:11,  3.03it/s]\n",
      "  8%|▊         | 3/37 [00:00<00:08,  4.11it/s]\n",
      " 11%|█         | 4/37 [00:01<00:06,  4.89it/s]\n",
      " 14%|█▎        | 5/37 [00:01<00:05,  5.69it/s]\n",
      " 16%|█▌        | 6/37 [00:01<00:04,  6.23it/s]\n",
      " 19%|█▉        | 7/37 [00:01<00:04,  6.93it/s]\n",
      " 22%|██▏       | 8/37 [00:01<00:04,  7.21it/s]\n",
      " 24%|██▍       | 9/37 [00:01<00:03,  7.60it/s]\n",
      " 27%|██▋       | 10/37 [00:01<00:03,  7.97it/s]\n",
      " 30%|██▉       | 11/37 [00:01<00:03,  8.24it/s]\n",
      " 32%|███▏      | 12/37 [00:01<00:02,  8.50it/s]\n",
      " 35%|███▌      | 13/37 [00:02<00:02,  8.91it/s]\n",
      " 41%|████      | 15/37 [00:02<00:02,  9.41it/s]\n",
      " 46%|████▌     | 17/37 [00:02<00:01, 10.03it/s]\n",
      " 51%|█████▏    | 19/37 [00:02<00:01, 10.26it/s]\n",
      " 57%|█████▋    | 21/37 [00:02<00:01, 10.83it/s]\n",
      " 62%|██████▏   | 23/37 [00:02<00:01, 11.69it/s]\n",
      " 68%|██████▊   | 25/37 [00:03<00:00, 12.39it/s]\n",
      " 73%|███████▎  | 27/37 [00:03<00:00, 13.22it/s]\n",
      " 78%|███████▊  | 29/37 [00:03<00:00, 13.59it/s]\n",
      " 84%|████████▍ | 31/37 [00:03<00:00, 14.18it/s]\n",
      " 89%|████████▉ | 33/37 [00:03<00:00, 14.76it/s]\n",
      " 95%|█████████▍| 35/37 [00:03<00:00, 15.43it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00,  9.77it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 42%|████▏     | 8/19 [00:00<00:00, 65.54it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 90.79it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]\n",
      "  3%|▎         | 1/37 [00:00<00:06,  5.21it/s]\n",
      "  5%|▌         | 2/37 [00:00<00:05,  6.13it/s]\n",
      "  8%|▊         | 3/37 [00:00<00:05,  6.63it/s]\n",
      " 11%|█         | 4/37 [00:00<00:04,  7.05it/s]\n",
      " 14%|█▎        | 5/37 [00:00<00:04,  7.55it/s]\n",
      " 16%|█▌        | 6/37 [00:00<00:03,  7.97it/s]\n",
      " 19%|█▉        | 7/37 [00:00<00:03,  8.33it/s]\n",
      " 22%|██▏       | 8/37 [00:01<00:03,  8.20it/s]\n",
      " 27%|██▋       | 10/37 [00:01<00:03,  8.82it/s]\n",
      " 30%|██▉       | 11/37 [00:01<00:02,  9.05it/s]\n",
      " 32%|███▏      | 12/37 [00:01<00:02,  9.19it/s]\n",
      " 35%|███▌      | 13/37 [00:01<00:02,  9.40it/s]\n",
      " 41%|████      | 15/37 [00:01<00:02,  9.78it/s]\n",
      " 46%|████▌     | 17/37 [00:01<00:01, 10.59it/s]\n",
      " 51%|█████▏    | 19/37 [00:02<00:01, 10.69it/s]\n",
      " 57%|█████▋    | 21/37 [00:02<00:01, 11.11it/s]\n",
      " 62%|██████▏   | 23/37 [00:02<00:01, 11.70it/s]\n",
      " 68%|██████▊   | 25/37 [00:02<00:00, 12.34it/s]\n",
      " 73%|███████▎  | 27/37 [00:02<00:00, 12.93it/s]\n",
      " 78%|███████▊  | 29/37 [00:02<00:00, 13.73it/s]\n",
      " 84%|████████▍ | 31/37 [00:02<00:00, 14.54it/s]\n",
      " 89%|████████▉ | 33/37 [00:03<00:00, 14.91it/s]\n",
      " 95%|█████████▍| 35/37 [00:03<00:00, 15.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.29it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 47%|████▋     | 9/19 [00:00<00:00, 84.93it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 101.16it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]\n",
      "  3%|▎         | 1/37 [00:00<00:19,  1.84it/s]\n",
      "  5%|▌         | 2/37 [00:00<00:10,  3.24it/s]\n",
      "  8%|▊         | 3/37 [00:00<00:07,  4.39it/s]\n",
      " 11%|█         | 4/37 [00:00<00:06,  5.14it/s]\n",
      " 14%|█▎        | 5/37 [00:01<00:05,  5.91it/s]\n",
      " 16%|█▌        | 6/37 [00:01<00:04,  6.60it/s]\n",
      " 19%|█▉        | 7/37 [00:01<00:04,  7.12it/s]\n",
      " 22%|██▏       | 8/37 [00:01<00:03,  7.76it/s]\n",
      " 24%|██▍       | 9/37 [00:01<00:03,  8.22it/s]\n",
      " 27%|██▋       | 10/37 [00:01<00:03,  8.63it/s]\n",
      " 30%|██▉       | 11/37 [00:01<00:02,  9.00it/s]\n",
      " 35%|███▌      | 13/37 [00:01<00:02,  9.69it/s]\n",
      " 41%|████      | 15/37 [00:02<00:02, 10.07it/s]\n",
      " 46%|████▌     | 17/37 [00:02<00:01, 10.48it/s]\n",
      " 51%|█████▏    | 19/37 [00:02<00:01, 11.42it/s]\n",
      " 57%|█████▋    | 21/37 [00:02<00:01, 11.38it/s]\n",
      " 62%|██████▏   | 23/37 [00:02<00:01, 12.02it/s]\n",
      " 68%|██████▊   | 25/37 [00:02<00:00, 12.77it/s]\n",
      " 73%|███████▎  | 27/37 [00:03<00:00, 13.59it/s]\n",
      " 78%|███████▊  | 29/37 [00:03<00:00, 14.21it/s]\n",
      " 84%|████████▍ | 31/37 [00:03<00:00, 14.85it/s]\n",
      " 89%|████████▉ | 33/37 [00:03<00:00, 15.76it/s]\n",
      " 95%|█████████▍| 35/37 [00:03<00:00, 16.22it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 10.41it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 47%|████▋     | 9/19 [00:00<00:00, 78.10it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 87.96it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 86.41it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]\n",
      "  3%|▎         | 1/37 [00:00<00:05,  6.05it/s]\n",
      "  5%|▌         | 2/37 [00:00<00:05,  6.98it/s]\n",
      "  8%|▊         | 3/37 [00:00<00:04,  7.72it/s]\n",
      " 11%|█         | 4/37 [00:00<00:04,  8.16it/s]\n",
      " 14%|█▎        | 5/37 [00:00<00:03,  8.52it/s]\n",
      " 16%|█▌        | 6/37 [00:00<00:03,  8.63it/s]\n",
      " 19%|█▉        | 7/37 [00:00<00:03,  8.94it/s]\n",
      " 24%|██▍       | 9/37 [00:01<00:02,  9.54it/s]\n",
      " 30%|██▉       | 11/37 [00:01<00:02, 10.12it/s]\n",
      " 35%|███▌      | 13/37 [00:01<00:02, 10.51it/s]\n",
      " 41%|████      | 15/37 [00:01<00:02, 10.90it/s]\n",
      " 46%|████▌     | 17/37 [00:01<00:01, 11.21it/s]\n",
      " 51%|█████▏    | 19/37 [00:01<00:01, 12.14it/s]\n",
      " 57%|█████▋    | 21/37 [00:02<00:01, 11.95it/s]\n",
      " 62%|██████▏   | 23/37 [00:02<00:01, 12.64it/s]\n",
      " 68%|██████▊   | 25/37 [00:02<00:00, 12.60it/s]\n",
      " 73%|███████▎  | 27/37 [00:02<00:00, 13.69it/s]\n",
      " 78%|███████▊  | 29/37 [00:02<00:00, 14.26it/s]\n",
      " 84%|████████▍ | 31/37 [00:02<00:00, 15.21it/s]\n",
      " 89%|████████▉ | 33/37 [00:02<00:00, 15.03it/s]\n",
      " 97%|█████████▋| 36/37 [00:02<00:00, 16.80it/s]\n",
      "100%|██████████| 37/37 [00:02<00:00, 12.34it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 42%|████▏     | 8/19 [00:00<00:00, 66.80it/s]Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "\n",
      "100%|██████████| 19/19 [00:00<00:00, 92.47it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]\n",
      "  3%|▎         | 1/37 [00:00<00:19,  1.81it/s]\n",
      "  5%|▌         | 2/37 [00:00<00:11,  3.18it/s]\n",
      "  8%|▊         | 3/37 [00:00<00:07,  4.34it/s]\n",
      " 11%|█         | 4/37 [00:00<00:06,  5.19it/s]\n",
      " 14%|█▎        | 5/37 [00:01<00:05,  5.99it/s]\n",
      " 16%|█▌        | 6/37 [00:01<00:04,  6.55it/s]\n",
      " 19%|█▉        | 7/37 [00:01<00:04,  6.97it/s]\n",
      " 22%|██▏       | 8/37 [00:01<00:03,  7.57it/s]\n",
      " 27%|██▋       | 10/37 [00:01<00:03,  8.67it/s]\n",
      " 32%|███▏      | 12/37 [00:01<00:02,  9.25it/s]\n",
      " 38%|███▊      | 14/37 [00:02<00:02,  9.44it/s]\n",
      " 43%|████▎     | 16/37 [00:02<00:02, 10.46it/s]\n",
      " 49%|████▊     | 18/37 [00:02<00:01, 10.70it/s]\n",
      " 54%|█████▍    | 20/37 [00:02<00:01, 11.04it/s]\n",
      " 59%|█████▉    | 22/37 [00:02<00:01, 11.91it/s]\n",
      " 65%|██████▍   | 24/37 [00:02<00:01, 12.90it/s]\n",
      " 70%|███████   | 26/37 [00:02<00:00, 14.01it/s]\n",
      " 76%|███████▌  | 28/37 [00:03<00:00, 14.62it/s]\n",
      " 81%|████████  | 30/37 [00:03<00:00, 15.62it/s]\n",
      " 86%|████████▋ | 32/37 [00:03<00:00, 16.17it/s]\n",
      " 95%|█████████▍| 35/37 [00:03<00:00, 17.41it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 10.64it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 47%|████▋     | 9/19 [00:00<00:00, 73.81it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 93.13it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]\n",
      "  3%|▎         | 1/36 [00:00<00:08,  4.04it/s]\n",
      "  6%|▌         | 2/36 [00:00<00:05,  5.68it/s]\n",
      "  8%|▊         | 3/36 [00:00<00:05,  6.39it/s]\n",
      " 11%|█         | 4/36 [00:00<00:04,  6.63it/s]\n",
      " 14%|█▍        | 5/36 [00:00<00:04,  7.24it/s]\n",
      " 17%|█▋        | 6/36 [00:00<00:03,  7.77it/s]\n",
      " 19%|█▉        | 7/36 [00:00<00:03,  7.86it/s]\n",
      " 22%|██▏       | 8/36 [00:01<00:03,  8.17it/s]\n",
      " 28%|██▊       | 10/36 [00:01<00:02,  8.84it/s]\n",
      " 33%|███▎      | 12/36 [00:01<00:02,  9.30it/s]\n",
      " 39%|███▉      | 14/36 [00:01<00:02,  9.91it/s]\n",
      " 44%|████▍     | 16/36 [00:01<00:02,  9.93it/s]\n",
      " 50%|█████     | 18/36 [00:02<00:01, 10.37it/s]\n",
      " 56%|█████▌    | 20/36 [00:02<00:01, 10.18it/s]\n",
      " 61%|██████    | 22/36 [00:02<00:01, 11.13it/s]\n",
      " 67%|██████▋   | 24/36 [00:02<00:01, 11.79it/s]\n",
      " 72%|███████▏  | 26/36 [00:02<00:00, 12.57it/s]\n",
      " 78%|███████▊  | 28/36 [00:02<00:00, 13.13it/s]\n",
      " 83%|████████▎ | 30/36 [00:02<00:00, 13.98it/s]\n",
      " 89%|████████▉ | 32/36 [00:03<00:00, 13.97it/s]\n",
      " 94%|█████████▍| 34/36 [00:03<00:00, 12.09it/s]\n",
      "100%|██████████| 36/36 [00:03<00:00, 10.57it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 37%|███▋      | 7/19 [00:00<00:00, 64.22it/s]\n",
      " 74%|███████▎  | 14/19 [00:00<00:00, 45.86it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 49.26it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]\n",
      "  3%|▎         | 1/37 [00:00<00:19,  1.88it/s]\n",
      "  5%|▌         | 2/37 [00:00<00:10,  3.29it/s]\n",
      "  8%|▊         | 3/37 [00:00<00:07,  4.51it/s]\n",
      " 11%|█         | 4/37 [00:00<00:05,  5.51it/s]\n",
      " 14%|█▎        | 5/37 [00:01<00:05,  6.03it/s]\n",
      " 16%|█▌        | 6/37 [00:01<00:04,  6.70it/s]\n",
      " 19%|█▉        | 7/37 [00:01<00:04,  7.42it/s]\n",
      " 22%|██▏       | 8/37 [00:01<00:03,  8.04it/s]\n",
      " 24%|██▍       | 9/37 [00:01<00:03,  8.54it/s]\n",
      " 30%|██▉       | 11/37 [00:01<00:02,  9.37it/s]\n",
      " 35%|███▌      | 13/37 [00:01<00:02, 10.13it/s]\n",
      " 41%|████      | 15/37 [00:02<00:02, 10.43it/s]\n",
      " 46%|████▌     | 17/37 [00:02<00:02,  9.71it/s]\n",
      " 51%|█████▏    | 19/37 [00:02<00:01, 10.63it/s]\n",
      " 57%|█████▋    | 21/37 [00:02<00:01, 11.38it/s]\n",
      " 62%|██████▏   | 23/37 [00:02<00:01, 12.61it/s]\n",
      " 68%|██████▊   | 25/37 [00:02<00:00, 13.33it/s]\n",
      " 73%|███████▎  | 27/37 [00:02<00:00, 14.42it/s]\n",
      " 78%|███████▊  | 29/37 [00:03<00:00, 15.11it/s]\n",
      " 84%|████████▍ | 31/37 [00:03<00:00, 16.05it/s]\n",
      " 89%|████████▉ | 33/37 [00:03<00:00, 16.74it/s]\n",
      " 97%|█████████▋| 36/37 [00:03<00:00, 18.05it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 10.82it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 47%|████▋     | 9/19 [00:00<00:00, 77.03it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 92.75it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]\n",
      "  3%|▎         | 1/36 [00:00<00:05,  6.25it/s]\n",
      "  6%|▌         | 2/36 [00:00<00:04,  7.08it/s]\n",
      "  8%|▊         | 3/36 [00:00<00:04,  7.42it/s]\n",
      " 11%|█         | 4/36 [00:00<00:04,  7.54it/s]\n",
      " 14%|█▍        | 5/36 [00:00<00:03,  7.99it/s]\n",
      " 17%|█▋        | 6/36 [00:00<00:03,  8.29it/s]\n",
      " 19%|█▉        | 7/36 [00:00<00:03,  8.49it/s]\n",
      " 22%|██▏       | 8/36 [00:00<00:03,  8.79it/s]\n",
      " 25%|██▌       | 9/36 [00:01<00:02,  9.13it/s]\n",
      " 31%|███       | 11/36 [00:01<00:02,  9.88it/s]\n",
      " 36%|███▌      | 13/36 [00:01<00:02, 10.34it/s]\n",
      " 42%|████▏     | 15/36 [00:01<00:01, 10.74it/s]\n",
      " 47%|████▋     | 17/36 [00:01<00:01, 11.17it/s]\n",
      " 53%|█████▎    | 19/36 [00:01<00:01, 11.73it/s]\n",
      " 58%|█████▊    | 21/36 [00:02<00:01, 11.88it/s]\n",
      " 64%|██████▍   | 23/36 [00:02<00:01, 12.84it/s]\n",
      " 69%|██████▉   | 25/36 [00:02<00:00, 13.68it/s]\n",
      " 75%|███████▌  | 27/36 [00:02<00:00, 14.49it/s]\n",
      " 81%|████████  | 29/36 [00:02<00:00, 15.05it/s]\n",
      " 86%|████████▌ | 31/36 [00:02<00:00, 15.73it/s]\n",
      " 92%|█████████▏| 33/36 [00:02<00:00, 16.52it/s]\n",
      "100%|██████████| 36/36 [00:02<00:00, 18.62it/s]\n",
      "100%|██████████| 36/36 [00:02<00:00, 12.20it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 42%|████▏     | 8/19 [00:00<00:00, 74.75it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 96.67it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# 使用subprocess.Popen启动一个子进程\n",
    "# 使用cmd.exe在Windows上，使用/bin/bash在Unix或Linux上\n",
    "shell_process = subprocess.Popen(\"cmd.exe\", stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "# 将命令发送到子进程\n",
    "stdout, stderr = shell_process.communicate(input=commands)\n",
    "\n",
    "# 打印命令输出\n",
    "print(stdout)\n",
    "\n",
    "# 如果有错误，打印错误\n",
    "if stderr:\n",
    "    print(stderr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ev4symProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
